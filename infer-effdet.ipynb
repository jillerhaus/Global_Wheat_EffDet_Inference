{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global-Wheat-Detection: EfficientDet Inference\n",
    "\n",
    "This is the inference notebook to my EfficientDet pipeline. It is based on Alex Shonenkov's [notebook](https://www.kaggle.com/shonenkov/inference-efficientdet), since before this I have never used EfficientDet and the documentation of the PyTorch implementation I am using is very spotty. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Detection\n",
    "\n",
    "This is to make sure the notebook works on both my own windows workstation as well as on the Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "system = os.name\n",
    "if system == 'posix':\n",
    "    kaggle = True\n",
    "    windows = False\n",
    "    print('running on kaggle')\n",
    "elif system == 'nt':\n",
    "    kaggle = False\n",
    "    windows = True\n",
    "    print('running on windows')\n",
    "else:\n",
    "    print('unknown system')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if windows:\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from glob import glob\n",
    "    import re\n",
    "    import cv2\n",
    "    import torch\n",
    "    from torch.utils.data import DataLoader\n",
    "    from effdet import get_efficientdet_config, EfficientDet, DetBenchPredict\n",
    "    from effdet.efficientdet import HeadNet\n",
    "    import gc\n",
    "    import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kaggle:\n",
    "    !pip install --no-deps '../input/timm-package/timm-0.1.26-py3-none-any.whl' > /dev/null\n",
    "#     !pip install --no-deps '../input/effdetgithub/'\n",
    "    !pip install --no-deps '../input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl' > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kaggle:\n",
    "    import sys\n",
    "    sys.path.insert(0, \"../input/timm-efficientdet-pytorch\")\n",
    "    sys.path.insert(0, \"../input/omegaconf\")\n",
    "    sys.path.insert(0, \"../input/weightedboxesfusion\")\n",
    "\n",
    "    from ensemble_boxes import *\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from glob import glob\n",
    "    from torch.utils.data import Dataset,DataLoader\n",
    "    import albumentations as A\n",
    "    from albumentations.pytorch.transforms import ToTensorV2\n",
    "    import cv2\n",
    "    import gc\n",
    "    from matplotlib import pyplot as plt\n",
    "    from effdet import get_efficientdet_config, EfficientDet, DetBenchEval\n",
    "    from effdet.efficientdet import HeadNet\n",
    "    import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of all test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'../input/global-wheat-detection/train'\n",
    "# path = f'../input/global-wheat-detection/test'\n",
    "jpg_paths = glob(f'{path}/*.jpg')\n",
    "jpgfilenames = [re.compile(r'([\\w\\_\\(\\)]*)\\.jpg').search(jpgpath).group(1) for jpgpath in jpg_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class configuration():\n",
    "    scale = 1\n",
    "    batch_size = 4\n",
    "    if windows:\n",
    "        cuda_device = 1\n",
    "    if kaggle:\n",
    "        cuda_device = 0\n",
    "    if kaggle:\n",
    "        gt = False\n",
    "        visualize = False\n",
    "        save = False\n",
    "    if windows:\n",
    "        gt = True\n",
    "        visualize = True\n",
    "        save = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DatasetRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriever for testing data\n",
    "class DatasetRetriever():\n",
    "    \n",
    "    def __init__(self, image_ids):\n",
    "        super().__init__()\n",
    "        self.image_ids = image_ids\n",
    "        self.scale = configuration.scale\n",
    "    def __getitem__(self, index: int):\n",
    "        filename = self.image_ids[index]\n",
    "        image = f'{path}/{filename}.jpg'\n",
    "        image = cv2.imread(image, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "        #resize the image\n",
    "        w_image = int(image.shape[1] * self.scale)\n",
    "        h_image = int(image.shape[0] * self.scale)\n",
    "#         dim = (w_image, h_image)\n",
    "        dim = (1024, 1024)\n",
    "        image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "        image = torch.tensor(image).permute(2,0,1)\n",
    "        \n",
    "        return image, filename\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_ids)\n",
    "    \n",
    "dr = DatasetRetriever(jpgfilenames)\n",
    "dr.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if configuration.gt == True:\n",
    "    nr_files = len(jpgfilenames)\n",
    "    class DatasetRetriever1():\n",
    "        def __init__(self, df, image_ids):\n",
    "            super().__init__()\n",
    "            self.image_ids = image_ids\n",
    "            self.df = df\n",
    "        def __getitem__(self, index:int):\n",
    "            #load the image\n",
    "            filename = self.image_ids[index][:-2]\n",
    "            flavor = self.image_ids[index][-2:]\n",
    "            filename = self.image_ids[index]\n",
    "            image = f'{path}/{filename}.jpg'\n",
    "            image = cv2.imread(image, cv2.IMREAD_COLOR)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "            image /= 255.0\n",
    "            #resize the image\n",
    "            dim = (1024, 1024)\n",
    "            image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "            image = torch.tensor(image).permute(2,0,1)\n",
    "            if filename in labels.image_id.values:\n",
    "                boxes = labels.loc[labels.image_id == filename,['x_min', 'y_min', 'x_max', 'y_max']]\n",
    "                boxes = torch.tensor(boxes.values)\n",
    "                boxes = boxes[:,[1,0,3,2]]\n",
    "                boxes = boxes.int()\n",
    "                lbls = torch.tensor(np.ones(boxes.shape[0], dtype = 'int32'))\n",
    "            else:\n",
    "                boxes = torch.tensor([])\n",
    "                lbls = torch.tensor([])\n",
    "            return image, dict(boxes = boxes, labels = lbls, image_id = torch.tensor([index])), filename\n",
    "        def __len__(self):\n",
    "            return len(self.image_ids)\n",
    "\n",
    "    labels = pd.read_csv('labels.csv')\n",
    "    dataset1 = DatasetRetriever1(df = labels, image_ids = jpgfilenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetRetriever(image_ids = jpgfilenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                          batch_size=configuration.batch_size,\n",
    "                                          pin_memory = False,\n",
    "                                          drop_last = False,\n",
    "                                          shuffle = False,\n",
    "                                          collate_fn = collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_net(checkpoint_path):\n",
    "    config = get_efficientdet_config('tf_efficientdet_d5')\n",
    "    net = EfficientDet(config = config, pretrained_backbone = False)\n",
    "    config.num_classes = 1\n",
    "    config.image_size = 1024 * configuration.scale\n",
    "    net.class_net = HeadNet(config, num_outputs = config.num_classes,\n",
    "                            norm_kwargs = dict(eps = .001, momentum = .01))\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    \n",
    "    del checkpoint\n",
    "    gc.collect()\n",
    "    if windows:\n",
    "        net = DetBenchPredict(net, config)\n",
    "    if kaggle:\n",
    "        net = DetBenchEval(net, config)\n",
    "    return net.cuda(configuration.cuda_device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chkpntpth = f'../../train/working/effdet-cutmix-augmix/last-checkpoint.bin'\n",
    "# chkpntpth = sorted(glob(f'../../train/working/effdet-cutmix-augmix/best-checkpoint-*epoch.bin'))[-1]\n",
    "if windows:\n",
    "    chkpntpth = sorted(glob(f'../../train/working/old/effdet-experimental/best-checkpoint-*epoch.bin'))[-1]\n",
    "if kaggle:\n",
    "    chkpntpth = f'../input/effdetweights/last-checkpoint.bin'\n",
    "# chkpntpth = f'../input/effdet-cutmix-augmix/last-checkpoint.bin'\n",
    "net = load_net(chkpntpth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(images, image_ids, score_threshold = 0.4):\n",
    "    images = torch.stack(images).cuda(configuration.cuda_device).float()\n",
    "    predictions = {'image_id':[],'conf': [],'boxes':[]}#, 'bad_conf':[], 'badboxes':[]}\n",
    "    \n",
    "    batch_size = images.shape[0]\n",
    "    images = images.cuda(configuration.cuda_device).float()\n",
    "    target_res = {}\n",
    "    target_res['img_scale'] = torch.tensor([1.0] * batch_size, dtype = torch.float32).cuda(configuration.cuda_device)\n",
    "    target_res['img_size'] = torch.tensor([images[0].shape[-2:]] * batch_size, dtype=torch.float32).cuda(configuration.cuda_device)\n",
    "    with torch.no_grad():\n",
    "        if windows:\n",
    "            det = net(images, target_res['img_scale'], target_res['img_size'])\n",
    "        if kaggle:\n",
    "            det = net(images, torch.tensor([1]*images.shape[0]).float().cuda())\n",
    "            \n",
    "        for i in range(images.shape[0]):\n",
    "            # the first four columns are the boundaries of the boxes and the last 2 are the \n",
    "            boxes = det[i].detach().cpu().numpy()[:,:4]\n",
    "            scores = det[i].detach().cpu().numpy()[:,4]\n",
    "            indexes = np.where(scores > score_threshold)[0]\n",
    "            boxes = boxes[indexes]\n",
    "            scores = scores[indexes]\n",
    "            if boxes.shape[0] < 5:\n",
    "                score_threshold = 0.6\n",
    "            else:\n",
    "                score_threshold = np.average(scores) - 0.2\n",
    "            indexes = np.where(scores > score_threshold)[0]\n",
    "            boxes = boxes[indexes]\n",
    "            scores = scores[indexes]\n",
    "            boxes[:, 2] = boxes[:, 2] + boxes[:, 0]\n",
    "            boxes[:, 3] = boxes[:, 3] + boxes[:, 1]\n",
    "            #predictions.append({'boxes': boxes[indexes],\n",
    "             #                 'scores': scores[indexes]})\n",
    "            predictions['boxes'].append(boxes)\n",
    "            predictions['conf'].append(scores)\n",
    "            predictions['image_id'].append(image_ids[i])\n",
    "#             predictions['bad_conf'].append()\n",
    "            \n",
    "    return predictions\n",
    "#     with torch.no_grad():\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if configuration.visualize == True:\n",
    "    m = 0\n",
    "    new_imagelist = []\n",
    "    inf_folder = f'./inference'\n",
    "    if configuration.save & (not os.path.exists(inf_folder)):\n",
    "                os.makedirs(inf_folder)\n",
    "    for j, (images, image_ids) in enumerate(data_loader):\n",
    "        predictions = make_predictions(images, image_ids)\n",
    "        df = pd.DataFrame(predictions)\n",
    "        for i in range(len(image_ids)):\n",
    "            ## plotting the inference\n",
    "            image_id = image_ids[i]\n",
    "            new_imagelist.append(image_id)\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(16, 16))\n",
    "            bx1 = df.iloc[i].boxes\n",
    "            conf1 = df.iloc[i].conf\n",
    "            sample = images[i].permute(1,2,0).cpu().numpy()\n",
    "            k = 0\n",
    "            for box in bx1:\n",
    "                cv2.rectangle(sample, (box[0], box[1]), (box[2], box[3]), (1, 0, 0), 1)\n",
    "                plt.text(box[2],box[1],f'{conf1[k]:.3f}', color = 'red', fontsize = 18)\n",
    "                k+=1\n",
    "            #Plotting the Ground Truth\n",
    "            if configuration.gt == True:\n",
    "                image1, target1, image_id1 = dataset1[m]\n",
    "                boxes1 = target1['boxes'].cpu().numpy().astype(np.int32)\n",
    "                for box1 in boxes1:\n",
    "                    cv2.rectangle(sample, (box1[1], box1[0]), (box1[3],  box1[2]), (0, 1, 0), 2)\n",
    "\n",
    "            #Showing and saving the picture\n",
    "            ax.set_axis_off()\n",
    "            ax.imshow(sample)\n",
    "            if windows & configuration.save:\n",
    "                plt.savefig(f'{inf_folder}/{image_ids[i]}.jpeg', transparent=True, bbox_inches = 'tight',\n",
    "                            facecolor = 'k',pad_inches = 0)\n",
    "            plt.show()\n",
    "            m+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(columns = ['image_id', 'PredictionString'])\n",
    "cols = ['conf', 'px_min', 'py_min', 'px_max', 'py_max']\n",
    "\n",
    "for j, (images, image_ids) in enumerate(data_loader):\n",
    "    predictions = make_predictions(images, image_ids)\n",
    "    df = pd.DataFrame(predictions)\n",
    "#     print('dataframe',df)\n",
    "    for i in range(len(image_ids)):\n",
    "        row = df.iloc[i]\n",
    "#         print('row',row)\n",
    "#         print(row)\n",
    "        filename = row.image_id\n",
    "        dataset = pd.DataFrame(columns = cols)\n",
    "        if len(row.conf) > 0:\n",
    "            for k in range(len(row.conf)):\n",
    "                row_df = pd.DataFrame([[row.conf[k],row.boxes[k][0],row.boxes[k][1],row.boxes[k][2],row.boxes[k][3]]], \n",
    "                                      columns = cols)\n",
    "                dataset = pd.concat([dataset, row_df], axis = 0, ignore_index = True)\n",
    "            dataset['width'] = 1024 * configuration.scale\n",
    "            dataset['height'] = 1024 * configuration.scale\n",
    "            dataset['px_box'] = dataset['px_max'] - dataset['px_min']\n",
    "            dataset['py_box'] = dataset['py_max'] - dataset['py_min']\n",
    "            dataset[['px_min', 'py_min', 'px_box', 'py_box']] = dataset[['px_min', 'py_min', 'px_box', 'py_box']].round().astype('int')\n",
    "            dataset.loc[dataset.width < dataset.px_min,'px_min'] = dataset.width -1\n",
    "            dataset.loc[dataset.height < dataset.py_min,'py_min'] = dataset.height -1\n",
    "            dataset.loc[1 > dataset.px_box,'px_box'] = 1\n",
    "            dataset.loc[1 > dataset.py_box,'py_box'] = 1\n",
    "            dataset.loc[0 > dataset.px_min,'px_min'] = 0\n",
    "            dataset.loc[0 > dataset.py_min,'py_min'] = 0\n",
    "            dataset.loc[dataset['px_min'] + dataset['px_box'] > dataset['width'], 'px_box'] = dataset['width'] - dataset['px_min'] - 1\n",
    "            dataset.loc[dataset['py_min'] + dataset['py_box'] > dataset['height'], 'py_box'] = dataset['height'] - dataset['py_min'] - 1\n",
    "            submission_cols = ['conf', 'px_min', 'py_min', 'px_box', 'py_box']\n",
    "            shape = dataset[submission_cols].shape\n",
    "            row1 = dataset[submission_cols].values.reshape(1,shape[0]*shape[1])\n",
    "            str_array = np.array2string(row1[0], formatter = {'float_kind': lambda x: '%.5f' % x}, max_line_width = 9e3)\n",
    "            str_array = re.compile(r'\\[([\\d\\s\\.]+)\\]').search(str_array).group(1)\n",
    "            vals = pd.DataFrame([[filename, str_array]], columns =['image_id', 'PredictionString'])\n",
    "        else:\n",
    "            vals = pd.DataFrame([[filename, '']], columns =['image_id', 'PredictionString'])\n",
    "        submission = pd.concat([submission,vals], axis = 0, ignore_index = True)\n",
    "        submission.PredictionString = submission.PredictionString.str.replace(r'(\\.0+)', '').str.replace('\\s+',' ')\n",
    "\n",
    "submission.to_csv('submission.csv', index = False, sep = ',')\n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
